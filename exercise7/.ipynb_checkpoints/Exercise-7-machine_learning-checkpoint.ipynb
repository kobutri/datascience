{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## Submission Date: 19/12/2022\n",
    "\n",
    "## Points: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> keywords:<font color='black'> \n",
    "    \n",
    "**Tasks:** regression, classification, clustering  \n",
    "**Algorithms:** linear regression, logistic regression, random forest, SVM, k-means  \n",
    "**Evaluation Measures:** RMSE, precision, recall, F1-score  \n",
    "**Concepts:** training and testing\n",
    "**R packages used:** tidyverse, rpart, randomForest, e1071, caret, mice, mltest  \n",
    "  \n",
    "  \n",
    "    \n",
    "The goal of this lab session is to get familar with various machine learning based tasks in R. Many packages in R have similar interface that uses a formula and other parameters.\n",
    "\n",
    "**formula:** is a way to express the form of a model. For example, suppose you have a response variable y and independent variables x1, x2 and x3. To express that y depends linearly on x1, x2 and x3 you would use the formula `y ~ x1 + x2 + x3.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "[Supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) is the machine learning task of inferring a function from labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "[Regression](https://en.wikipedia.org/wiki/Regression_analysis) is the processes to estimate the relationships between a dependent variable (often called the 'outcome variable') and one or more independent variables (often called 'predictors', 'covariates', or 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**\n",
    "\n",
    "We will use the `lm()` function in the `stats` package which is part of base R. No external package needed.\n",
    "\n",
    "    lm_model <- lm(y ∼ x1 + x2, data=mydata)\n",
    "    summary(lm_model)\n",
    "\n",
    "The vector of coefficients for the model is contained in `lm_model$coefficients.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: We will start with building a simple model using the `cars` dataset that comes with R. The dataset contains the speed of cars and the distances taken to stop. In this example, we will build a linear regression model with only a **single feature**, i.e. to compute `dist` from `speed.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>speed</th><th scope=col>dist</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>4</td><td> 2</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>4</td><td>10</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>7</td><td> 4</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>7</td><td>22</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>8</td><td>16</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>9</td><td>10</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & speed & dist\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 4 &  2\\\\\n",
       "\t2 & 4 & 10\\\\\n",
       "\t3 & 7 &  4\\\\\n",
       "\t4 & 7 & 22\\\\\n",
       "\t5 & 8 & 16\\\\\n",
       "\t6 & 9 & 10\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | speed &lt;dbl&gt; | dist &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 | 4 |  2 |\n",
       "| 2 | 4 | 10 |\n",
       "| 3 | 7 |  4 |\n",
       "| 4 | 7 | 22 |\n",
       "| 5 | 8 | 16 |\n",
       "| 6 | 9 | 10 |\n",
       "\n"
      ],
      "text/plain": [
       "  speed dist\n",
       "1 4      2  \n",
       "2 4     10  \n",
       "3 7      4  \n",
       "4 7     22  \n",
       "5 8     16  \n",
       "6 9     10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view some first rows of the dataset\n",
    "head(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.0      \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.5 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8      \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.10\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.1      \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.5.0 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3      \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2 \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[1m\u001b[22m`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAAQlBMVEUAAAAzMzMzZv89PT1N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\nLIZhwgzBYhgmzPw/ygCpJs2YixAAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now, lets visually examine the data\n",
    "\n",
    "# load the required packages for plotting\n",
    "library(tidyverse)\n",
    "# draw the scatter plot between 'speed' and 'dist'\n",
    "ggplot(data = cars, mapping = aes(x = speed, y = dist)) +\n",
    "    geom_point() +\n",
    "    geom_smooth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above plot suggests that 'dist' can be computed from 'speed' through a linear function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a linear regression model\n",
    "cars_lm <- lm(dist ~ speed, data = cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the fitted model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## summary of fitted model\n",
    "summary(cars_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the fitted model for prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example unseen data\n",
    "df <- data.frame('speed' = c(2,3,4,7))\n",
    "# prediction\n",
    "predict(cars_lm, newdata = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: We will use another dataset that comes with R, `mtcars`, to build a model with **multiple features** to predict the fuel consumption `mpg.` The features describe different aspects of an automobile design and performance. We will also explore **which features to use**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(mtcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the dataset mtcars to create a linear regression model to predict `mpg` using `wt, qsec, am` and `carb`. \n",
    "mtcars_lm <- lm(mpg ~ wt + qsec + am + carb, data = mtcars)\n",
    "summary(mtcars_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "[Classification](https://en.wikipedia.org/wiki/Statistical_classification) is the problem of determining label(s) (e.g., categories or clasesses, etc.) of each data observation based on learning from labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widely used (shallow) classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Logistic Regression**](https://en.wikipedia.org/wiki/Logistic_regression)\n",
    "\n",
    "Provided in `stats` package, which is automatically loaded when starting R  \n",
    "\n",
    "    glm_model <- glm(y ∼ x1 + x2, family = binomial, data = mydata)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**K-Nearest Neighbor**](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "\n",
    "Install and load the `class` package\n",
    "\n",
    "    knn_model <- knn(train=X_train, test=X_test, cl=as.factor(labels), k=K)\n",
    "    \n",
    "`knn_model` is a factor vector of class attributes for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Decision Trees (CART)**](https://en.wikipedia.org/wiki/Decision_tree_learning)\n",
    "\n",
    "Install and load the `rpart` package.\n",
    "\n",
    "    cart_model <- rpart(y ∼ x1 + x2, data=mydata, method=\"class\")\n",
    " \n",
    "You can use `plot.rpart` and `text.rpart` to plot the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Random Forest**](https://en.wikipedia.org/wiki/Random_forest)\n",
    "\n",
    "Install and load the `randomForest` package\n",
    "\n",
    "\n",
    "    rf_model <- randomForest(y ~ x1 + x2, data=train, importance=TRUE, ntree=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Support Vector Machines (SVM)**](https://en.wikipedia.org/wiki/Support-vector_machine)\n",
    "\n",
    "Install and load the `e1071` package.\n",
    "\n",
    "    svm_model <- svm(x=X, y=as.factor(labels), kernel =\"radial\", cost=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: we will use the above models to predict `survivors` in the [Titanic dataset](https://www.kaggle.com/c/titanic). The dataset also provided in `titanic.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, view data examples, and summarize the dataset\n",
    "titanic <- read_csv('titanic.csv', skip=5)\n",
    "head(titanic)\n",
    "summary(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: most models do not work with `character` type, we need to convert strings to factors for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic$Sex <- as.factor(titanic$Sex)\n",
    "titanic$Cabin <- as.factor(titanic$Cabin)\n",
    "titanic$Embarked <- as.factor(titanic$Embarked)\n",
    "titanic$Survived <- as.factor(titanic$Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Testing data**\n",
    "\n",
    "split the titanic data into training and testing sets based on the feature we want to predict `Survived`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_training <- filter(titanic, !is.na(Survived))\n",
    "dim(titanic_training)\n",
    "titanic_testing <- filter(titanic, is.na(Survived))\n",
    "dim(titanic_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is missing value in training data\n",
    "summary(titanic_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is missing value in test data\n",
    "summary(titanic_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting `Survived` based on `Pclass` and `Sex` using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "titanic_glm <- glm(Survived ~ Pclass + Sex, data = titanic_training, family = binomial)\n",
    "\n",
    "# examine the model\n",
    "summary(titanic_glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the trained model for predict the survivor in test set\n",
    "titanic_testing$Survived <- predict(titanic_glm, titanic_testing, type=\"response\") # Question: why type=\"response\"\n",
    "titanic_testing$Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 -- 2 points\n",
    "\n",
    "Train a `random forest` model for predicting  `Survived` based only on  `Pclass`, `Age` and `Sex`, then apply the model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# install.packages('randomForest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "#### Measures of goodness\n",
    "We trained and applied some models to predict labels for un-labeled data, but how can we say if the model is good?\n",
    "\n",
    "The goodness of prediction models are measured w.r.t some dataset with groudtruth -- i.e., we need the labels for observations in test data. Typical measures for the goodness of the classification models are [Precision, Recall](https://en.wikipedia.org/wiki/Precision_and_recall), and [F1 scores](https://en.wikipedia.org/wiki/F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: we will train a model and evaluate its performance using [Iris dataset](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "iris <- read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', col_names = FALSE)\n",
    "\n",
    "# name the columns\n",
    "names(iris) <- c('sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view some rows\n",
    "head(iris)\n",
    "\n",
    "# view columns's data type\n",
    "str(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert `class` from string to factor\n",
    "iris$class <- as.factor(iris$class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the models, often we **divide** the set of labeled data into **training and test sets**. The models will be **trained on the training set**, and **evaluated using the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the iris dataset into: 80% for training set and the remaining 20% for test set \n",
    "training_size <- floor(0.8 * nrow(iris))\n",
    "train_indexes <- sample(seq_len(nrow(iris)), size = training_size)\n",
    "iris_train <- iris[train_indexes, ]\n",
    "iris_test <- iris[-train_indexes, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a svm model to predict `class` from `sepal_length` and `sepal_width`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install and load the 'e1071' package if not yet\n",
    "# install.packages('e1071')\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the features\n",
    "features <- c('sepal_length', 'sepal_width')\n",
    "# train a svm model\n",
    "svm_model <- svm(x=iris_train[features], y=iris_train$class, kernel =\"linear\", cost=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate the trained model using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install and load the 'mltest' package if not yet\n",
    "# install.packages('mltest', repos = 'https://cran.r-project.org/')\n",
    "library(mltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction\n",
    "predicted_labels <- as.factor(predict(svm_model, iris_test[features]))\n",
    "\n",
    "# get the groundtruth\n",
    "true_labels <- as.factor(iris_test$class)\n",
    "\n",
    "# measure the performance\n",
    "classifier_metrics <- ml_test(predicted_labels, true_labels, output.as.table = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall classification accuracy\n",
    "classifier_metrics$accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision for classes\n",
    "classifier_metrics$precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall for classes\n",
    "classifier_metrics$recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-measures for classes\n",
    "classifier_metrics$F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 -- 3 points\n",
    "\n",
    "Divide the iris dataset into training and test sets by ratio 9:1.Then train an SVM model to predict `class` using all features, and examine the performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# divide the iris dataset into training and test sets by ratio 90:10\n",
    "\n",
    "# set the features\n",
    "\n",
    "# train a svm model\n",
    "\n",
    "\n",
    "# get the prediction\n",
    "\n",
    "\n",
    "# get the groundtruth\n",
    "\n",
    "\n",
    "# measure the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "[Unsupervised machine learning](https://en.wikipedia.org/wiki/Unsupervised_learning) is the machine learning task of uncovering the hidden structure from \"unlabeled\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Means Clustering**\n",
    "    \n",
    "    kmeans_model <- kmeans(x=X, centers=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this exercise, we will use movies data on the [MovieLens 100K Dataset](http://files.grouplens.org/datasets/movielens/ml-100k/u.item) collected from the [MovieLens web site](http://movielens.org). It is available in the file `movies.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies <- read_delim('movies.txt', delim = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspecting and preprocessing\n",
    "\n",
    "# check top records\n",
    "head(movies)\n",
    "\n",
    "# remove duplicates\n",
    "movies <- distinct(movies)\n",
    "\n",
    "# Mow many movies are tagged as Comedy\n",
    "filter(movies, Comedy == 1) %>% count()\n",
    "\n",
    "# How many movies are tagged as Romance and Drama?\n",
    "filter(movies, Romance == 1 & Drama == 1) %>% count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a k-means cluster\n",
    "k = 5\n",
    "iters = 1000\n",
    "set.seed(1)\n",
    "\n",
    "movies <- select(movies, -Title)\n",
    "movie_kmeans <- kmeans(movies, centers = k, iter.max=iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Clustering Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view clustering output\n",
    "str(movie_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster vector, i.e., cluster index of each row\n",
    "movie_kmeans$cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid values\n",
    "movie_kmeans$centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of clusters, i.e., number of movies in each cluster\n",
    "movie_kmeans$size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within-cluster sum of squares\n",
    "movie_kmeans$withinss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determining number of clusters**\n",
    "\n",
    "One way to select the number of clusters is by using a **scree plot**. A standard scree plot has the number of clusters on the x-axis, and the sum of the within-cluster sum of squares on the y-axis. The within-cluster sum of squares for a cluster is the sum, across all points in the cluster, of the squared distance between each point and the centroid of the cluster. To determine the best number of clusters using this plot, we want to look for a bend, or elbow, in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(99)\n",
    "\n",
    "# Call kmeans function with centers = 3, centers = 4, etc\n",
    "num_clusters = seq(5, 15,1)\n",
    "\n",
    "# within-cluster sum of squares for all clusters\n",
    "sum_withinss = sapply(num_clusters, function(x) sum(kmeans(movies, centers=x, iter.max=2000)$withinss))\n",
    "\n",
    "# visualize\n",
    "ggplot(mapping = aes(x=num_clusters, y=sum_withinss)) +\n",
    "    geom_line() +\n",
    "    geom_point()\n",
    "    \n",
    "# 12 seems like a good pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[Top 10 algorithms in data mining](http://www.cs.uvm.edu/~icdm/algorithms/10Algorithms-08.pdf)\n",
    "\n",
    "[R for Statistical Learning](https://daviddalpiaz.github.io/r4sl/)\n",
    "\n",
    "[The caret Package](http://topepo.github.io/caret/)\n",
    "\n",
    "[Linear Regression: r-statistics.co](http://r-statistics.co/Linear-Regression.html)\n",
    "\n",
    "[Tutorial: SVM in R](http://math.stanford.edu/~yuany/course/2015.fall/SVM_in_R.pdf)\n",
    "\n",
    "[Artificial Neural Networks in R](https://rpubs.com/julianhatwell/annr)\n",
    "\n",
    "[Cluster analysis in R: determine the optimal number of clusters](https://stackoverflow.com/questions/15376075/cluster-analysis-in-r-determine-the-optimal-number-of-clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
